# ğŸ Python Library

[TOC]

pandas

numpy

seaborn

matplotlib.pyplot

from mlxtend.frequent_patterns import apriori
from mlxtend.frequent_patterns import association_rules
import mlxtend as ml





### missingno

- í•¨ìˆ˜ `matrix()` ê²°ì¸¡ ë°ì´í„°ë¥¼ ì‹œê°í™” 
  - ê²°ì¸¡ëœ ë°ì´í„°ëŠ” í°ìƒ‰ìœ¼ë¡œ, ê·¸ë ‡ì§€ ì•Šì€ ë°ì´í„°ëŠ” ê²€ì€ìƒ‰ìœ¼ë¡œ
  - ìŠ¤íŒŒí¬ë¼ì¸(spark line): ê° í–‰ì˜ ë°ì´í„° ì™„ì„±ë„

- í•¨ìˆ˜ `bar` ê° ì—´ì— ê²°ì¸¡ ë°ì´í„°ê°€ ì–¼ë§ˆë‚˜ ì¡´ì¬í•˜ëŠ”ì§€ ì‹œê°í™”

<br>

### pandas

- ë©”ì„œë“œ `dropna()` ê²°ì¸¡ ë°ì´í„°ê°€ ì¡´ì¬í•˜ëŠ” í–‰ì´ë‚˜ ì—´ ì§€ìš°ê¸°
  - ì¸ìˆ˜ `axis=1` ê²°ì¸¡ ë°ì´í„°ê°€ ìˆëŠ” ì—´ì„ ì œê±°
  - ì¸ìˆ˜ `thresh=7` 7ê°œ ì´ìƒì˜ ë¹„ê²°ì¸¡ ë°ì´í„°ê°€ ìˆëŠ” í–‰ ë˜ëŠ” ì—´ë§Œ ë‚¨ê¸°ê¸°

<br>

### scikit-learn

- í´ë˜ìŠ¤ `SimpleImputer` : ê²°ì¸¡ ë°ì´í„°ë¥¼ ëŒ€ì²´
  - ì¸ìˆ˜ `strategy` ëŒ€ì²´ê°’ ì„¤ì • (= `"mean" `/ `"median"` / `"most_frequent"`)
  - ë©”ì„œë“œ `fit_transform` ëŒ€ì²´ê°’ì´ ì±„ì›Œì‹  ë°ì´í„°í”„ë ˆì„ì„ ìƒì„±

```python
from sklearn.impute import SimpleImputer

imputer = SimpleImputer(strategy="most_frequent")
df = pd.DataFrame(imputer.fit_transform(df), columns=df.columns)
```

**preprocessing ì„œë¸ŒíŒ¨í‚¤ì§€**

- í´ë˜ìŠ¤`StandardScaler` : ìŠ¤ì¼€ì¼ë§ ë° ë³€ìˆ˜ë³€í™˜
  - ë©”ì„œë“œ `fit()` í‰ê· ê°’ê³¼ í‘œì¤€í¸ì°¨ë¥¼ ê³„ì‚°í•˜ì—¬ ê°ì²´ë‚´ì— ì €ì¥
  - ë©”ì„œë“œ `transform()` ì €ì¥í•œ ê°’ì„ í† ëŒ€ë¡œ ìƒˆë¡œìš´ í‰ê· ê°’ì´ 0, ìƒˆë¡œìš´ í‘œì¤€í¸ì°¨ê°€ 1ì´ ë˜ë„ë¡ ë°ì´í„°ë¥¼ ë³€í™˜í•˜ì—¬ ì¶œë ¥
  - ë©”ì„œë“œ `fit_transform()` ìœ„ì˜ ê³¼ì •ì„ í•œêº¼ë²ˆì—

```python
from sklearn.preprocessing import StandardScaler

scaler = StandardScaler()
scaler.fit_transform(X)
```

- í´ë˜ìŠ¤ `RobustScaler` :ì¤‘ì•™ê°’ì´ 0, IQR(interquartile range)ì´ 1ì´ ë˜ë„ë¡ ë³€í™˜

```python
from sklearn.preprocessing import RobustScaler

scaler = RobustScaler()
scaler.fit_transform(X)
```

- í´ë˜ìŠ¤ `FunctionTransformer` : ë°ì´í„° ë³€í™˜ - ì‚¬ìš©ìê°€ ì§€ì •í•œ í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•˜ì—¬ ì…ë ¥ê°’ì„ ë³€í™˜
- í´ë˜ìŠ¤ `PolynomialFeatures` : ë°ì´í„° ë³€í™˜ - ì…ë ¥ë°ì´í„°ë¥¼ ì—¬ëŸ¬ ê°œì˜ ë‹¤í•­ì‹ìœ¼ë¡œ ë³€í™˜
  - ì¸ìˆ˜ `degree` ì°¨ìˆ˜
  - ì¸ìˆ˜ `include_bias` ìƒìˆ˜í•­ ìƒì„± ì—¬ë¶€

```python
from sklearn.preprocessing import PolynomialFeatures

poly = PolynomialFeatures(degree=2)
poly.fit_transform(X)
```



<br>

### sns

- í•¨ìˆ˜ `countplot` ë°ì´í„° ë¶„í¬ ì‹œê°í™”

<br>

### patsy

ë°ì´í„°í”„ë ˆì„ì—ì„œ ì›í•˜ëŠ” ë°ì´í„°ë§Œ ì„ íƒí•˜ê±°ë‚˜ ìƒˆë¡œìš´ ë°ì´í„°ë¥¼ ì¡°í•© ìƒì„±

- í•¨ìˆ˜ `demo_data()` 

  - xë¡œ ì‹œì‘í•˜ëŠ” ë³€ìˆ˜ì— ëŒ€í•´ ì„ì˜ì˜ ì‹¤ìˆ˜ ë°ì´í„°ë¥¼ ìƒì„±
  - ë°ì´í„° í”„ë ˆì„ì— ìƒìˆ˜í•­ì„ ì¶”ê°€í•˜ê±°ë‚˜ ì›í•˜ëŠ” ë°ì´í„°ë§Œ ì„ íƒí•˜ê±°ë‚˜ ë³€í˜•

  - ëª¨í˜• ì •ì˜ ë¬¸ìì—´ `formula`
    - ì§€ì •í•œ ëŒ€ë¡œ ë³€í™˜ëœ ë°ì´í„° ì¶œë ¥
    - ì„ íƒí•˜ê³ ì í•˜ëŠ” ë°ì´í„° ì—´ ì´ë¦„ì„ `+`ë¡œ ì—°ê²°: í•´ë‹¹ ë°ì´í„°ë§Œ ë½‘ì•„ì¤€ë‹¤

```python
df = pd.DataFrame(demo_data("x1", "x2", "x3", "x4", "x5"))

# ì „ì²´ ë°ì´í„° ì¤‘ x1ë§Œì„ ë½‘ê¸°
dmatrix("x1 + 0", data=df)

# ì „ì²´ ë°ì´í„° ì¤‘ x1, x2, x3ë¥¼ ë½‘ê¸°
dmatrix("x1 + x2 + x3 + 0", data=df)

# 1ë¡œ êµ¬ì„±ëœ ìƒìˆ˜í•­ì„ ë„£ì§€ ì•Šê¸°
dmatrix("x1 + x2 + x3", data=df)
dmatrix("x1 + x2 + x3 - 1", data=df)

# ìˆ˜í•™ ë³€í™˜
dmatrix("x1 + np.log(np.abs(x2))", df)

# ìƒí˜¸ì‘ìš©(interaction)
dmatrix("x1 + x2 + x1:x2 + 0", df)
dmatrix("x1 * x2 + 0", df)

# ìƒí˜¸ì‘ìš©ì„ ì œì™¸í•œ ê²½ìš°ì—ëŠ”ì—°ì‚°ê³¼ì •ì„ ëª…ì‹œ
dmatrix("x1 + x2 + I(x1 + x2) + 0", df)
```

**ìŠ¤ì¼€ì¼ë§(scaling)** ì¡°ê±´ìˆ˜ì˜ ì˜í–¥ì„ ì¤„ì´ê¸° ìœ„í•´ í‰ê· ì„ 0ìœ¼ë¡œ í‘œì¤€í¸ì°¨ë¥¼ 1ìœ¼ë¡œ ë§Œë“œëŠ” ì‘ì—…

- í•¨ìˆ˜ `center()`í‰ê· ì„ 0ìœ¼ë¡œ ìŠ¤ì¼€ì¼ë§
- í•¨ìˆ˜ `standardize()` / í•¨ìˆ˜ `scale()` í‰ê· ì„ 0ìœ¼ë¡œí•˜ê³  í‘œì¤€í¸ì°¨ë¥¼ 1ë¡œ ìŠ¤ì¼€ì¼ë§

```python
dm = dmatrix("center(x1) + 0", df)

# í‰ê· ê°’ ì €ì¥
dm.design_info.factor_infos
```

